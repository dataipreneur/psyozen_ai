{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFbQCRIqgDhH",
        "outputId": "bf4c2f09-166e-42e6-b305-1813b06ea165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement streamlit-audio-recorder (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for streamlit-audio-recorder\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: audio_recorder_streamlit in /usr/local/lib/python3.10/dist-packages (0.0.10)\n",
            "Requirement already satisfied: streamlit>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from audio_recorder_streamlit) (1.38.0)\n",
            "Requirement already satisfied: altair<5 in /usr/local/lib/python3.10/dist-packages (from audio_recorder_streamlit) (4.2.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5->audio_recorder_streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<5->audio_recorder_streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5->audio_recorder_streamlit) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair<5->audio_recorder_streamlit) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair<5->audio_recorder_streamlit) (2.1.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5->audio_recorder_streamlit) (0.12.1)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (24.1)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (4.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio_recorder_streamlit) (4.0.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<5->audio_recorder_streamlit) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio_recorder_streamlit) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair<5->audio_recorder_streamlit) (1.16.0)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.7.4)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-b9j5dueq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-b9j5dueq\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=1ced73a218bdbe6222f2d6955f57ac1e8eb86066cf3471984daf0e0fef2cd931\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q19661kn/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "  Attempting uninstall: openai-whisper\n",
            "    Found existing installation: openai-whisper 20231117\n",
            "    Uninstalling openai-whisper-20231117:\n",
            "      Successfully uninstalled openai-whisper-20231117\n",
            "Successfully installed openai-whisper-20231117\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf-keras) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.42.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.106)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain.llms (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain.llms\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement langchain.prompts (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain.prompts\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement langchain.chains (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain.chains\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement langchain.memory (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain.memory\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.2.35)\n",
            "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (0.1.106)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph) (2.20.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (1.2.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.35)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.106)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.10/dist-packages (0.0.64)\n",
            "Requirement already satisfied: langchain-community<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.2.35)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.14)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.1.106)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.106)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.106)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ollama_client (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ollama_client\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.2.35)\n",
            "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (0.1.106)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.27->langgraph) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph) (2.20.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (1.2.2)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama) (0.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "#Installing libraries\n",
        "\n",
        "#main.py\n",
        "!pip install -q streamlit openai-whisper\n",
        "!pip install -q streamlit-audio-recorder\n",
        "!pip install -q pyttsx3\n",
        "!pip install -q python-dotenv\n",
        "!pip install audio_recorder_streamlit\n",
        "!pip install gTTS\n",
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n",
        "\n",
        "#emotion analyzer\n",
        "!pip install SpeechRecognition transformers torch\n",
        "!pip install tf-keras\n",
        "\n",
        "#llm agent\n",
        "!pip install langchain openai langgraph langsmith\n",
        "!pip install python-dotenv\n",
        "!pip install langchain.llms\n",
        "!pip install langchain.prompts\n",
        "!pip install langchain.chains\n",
        "!pip install langchain.memory\n",
        "!pip install langgraph\n",
        "!pip install langchain_community\n",
        "!pip install langchain_experimental\n",
        "!pip install --upgrade langchain\n",
        "!pip install --upgrade langsmith\n",
        "!pip install ollama_client\n",
        "!pip install langgraph\n",
        "!pip install ollama\n",
        "!pip install -q openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4jJstmngFK6",
        "outputId": "70aadd3e-ca76-4687-89ba-cc1ba4337d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "#Importing libraries\n",
        "\n",
        "#main.py\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import openai\n",
        "import dotenv\n",
        "import streamlit as st\n",
        "#from openai import OpenAI\n",
        "from audio_recorder_streamlit import audio_recorder\n",
        "import pyttsx3\n",
        "from io import BytesIO\n",
        "from gtts import gTTS\n",
        "import whisper\n",
        "import logging\n",
        "\n",
        "#emotion analyzer\n",
        "import speech_recognition as sr\n",
        "from transformers import pipeline\n",
        "\n",
        "#llm agent\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langgraph.graph import Graph\n",
        "from langchain.smith import RunEvalConfig, run_on_dataset\n",
        "from langsmith import Client\n",
        "from langchain.callbacks.tracers import LangChainTracer\n",
        "from langchain.llms import Ollama\n",
        "from langgraph.graph import StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "#llm agent\n",
        "#set Enviroment\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"<lamg_chain_url>\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"<langsmith_api_key>\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<open_ai_key>\"\n",
        "\n",
        "\n",
        "#Load environment variables\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "#client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "#client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "  # It's better to use environment variables for API keys\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "#client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "#def text_to_speech(text):\n",
        "#    engine = pyttsx3.init()\n",
        "#    engine.save_to_file(text, 'response.mp3')\n",
        "#    engine.runAndWait()\n",
        "#\n",
        "\n",
        "\n",
        "#llm agent\n",
        "\n",
        "\n",
        "#Bot Config\n",
        "\n",
        "summary_config = [{\"Current Summary\": \"\", \"Prompt\": \"Hello, I'm PsyOzen AI. How can I help you today?\", \"Text\": \"\", \"New Summary\": \"There doesnt seem to be enough imformation for new summary. Need to ask user to say something in a polite way.\"}, { \"Current Summary\": \"First Message\", \"Prompt\": \"Hello, I'm PsyOzen AI. How can I help you today?\", \"Text\": \"Hi, I'm Tom. My wife Emma and I are seriously considering divorce after 15 years of marriage. We're both at our wit's end.\", \"New Summary\": \"Tom and his wife Emma are contemplating divorce after 15 years of marriage. The situation appears dire.\" }, { \"Current Summary\": \"Tom and his wife Emma are contemplating divorce after 15 years of marriage. The situation appears dire.\", \"Prompt\": \"I understand you're going through a difficult time, Tom. We will focus on how our thoughts affect our feelings and behaviors. Can you identify a specific situation recently that led to conflict between you and Emma?\", \"Text\": \"Last night, Emma asked me about my day at work. I gave a short answer because I was tired. She then said, 'You never want to talk to me anymore.' I felt attacked and just walked away. We ended up not speaking for the rest of the evening.\", \"New Summary\": \"Tom describes a recent conflict where his short response to Emma's question about his day led to her expressing frustration about his communication. Tom felt attacked and withdrew, resulting in an evening of silence. This situation demonstrates negative thought patterns and behaviors that CBT can address.\" }, { \"Current Summary\": \"Tom describes a recent conflict where his short response to Emma's question about his day led to her expressing frustration about his communication. Tom felt attacked and withdrew, resulting in an evening of silence. This situation demonstrates negative thought patterns and behaviors that CBT can address.\", \"Prompt\": \"Thank you for sharing that, Tom. Let's break this down. What thoughts went through your mind when Emma said, 'You never want to talk to me anymore'?\", \"Text\": \"I thought, 'She's always criticizing me. Nothing I do is ever good enough for her. She doesn't understand how hard I work.' It made me feel angry and unappreciated.\", \"New Summary\": \"Tom's automatic thoughts in response to Emma's comment include beliefs about constant criticism, inadequacy, and lack of understanding. These thoughts led to feelings of anger and being unappreciated, resulting in withdrawal behavior. This cognitive pattern is a key focus for CBT intervention.\" }, { \"Current Summary\": \"Tom's automatic thoughts in response to Emma's comment include beliefs about constant criticism, inadequacy, and lack of understanding. These thoughts led to feelings of anger and being unappreciated, resulting in withdrawal behavior. This cognitive pattern is a key focus for CBT intervention.\", \"Prompt\": \"I see. Now, let's examine these thoughts. Are they factually true? Are there any exceptions to 'She's always criticizing me' or 'Nothing I do is ever good enough'?\", \"Text\": \"Well, when you put it that way... I guess she does compliment me sometimes, especially about how I am with the kids. And she was supportive when I got that promotion last year. Maybe 'always' and 'nothing' are too strong.\", \"New Summary\": \"Through CBT questioning, Tom recognizes that his automatic thoughts contain cognitive distortions, specifically overgeneralization. He acknowledges exceptions to his beliefs about constant criticism and inadequacy. This realization opens the door for cognitive restructuring and behavior modification.\" } ]\n",
        "\n",
        "\n",
        "response_config = [{\"Current Summary\": \"There doesnt seem to be enough imformation for new summary. Need to ask user for input in a polite way.\", \"Text\": \"\", 'Response': \"It seems you haven't shared the purpose of your presence here today.\"}, {'Current Summary': \"Tom and his wife Emma are contemplating divorce after 15 years of marriage. The situation appears critical and requires CBT intervention.\", 'Text': \"Hi, I'm Tom. My wife Emma and I are seriously considering divorce after 15 years of marriage. We're both at our wit's end.\", 'Response': \"I understand you're going through a difficult time, Tom. We will focus on how our thoughts affect our feelings and behaviors. This approach can be very helpful in addressing relationship issues. To start, it would be helpful to examine a specific situation that led to conflict between you and Emma.\" }, { 'Current Summary': \"Tom describes a recent conflict where his short response to Emma's question about his day led to her expressing frustration about his communication. Tom felt attacked and withdrew, resulting in an evening of silence. This situation demonstrates negative thought patterns and behaviors that CBT can address.\", 'Text': \"Last night, Emma asked me about my day at work. I gave a short answer because I was tired. She then said, 'You never want to talk to me anymore.' I felt attacked and just walked away. We ended up not speaking for the rest of the evening.\", 'Response': \"Thank you for sharing that specific example. Let's break this down into thoughts, feelings, and behaviors. You've described your behavior (giving a short answer and walking away) and Emma's response. Now, let's focus on your thoughts. What went through your mind when Emma said, 'You never want to talk to me anymore'?\" }, { 'Current Summary': \"Tom's automatic thoughts in response to Emma's comment include beliefs about constant criticism, inadequacy, and lack of understanding. These thoughts led to feelings of anger and being unappreciated, resulting in withdrawal behavior. This cognitive pattern is a key focus for CBT intervention.\", 'Text': \"I thought, 'She's always criticizing me. Nothing I do is ever good enough for her. She doesn't understand how hard I work.' It made me feel angry and unappreciated.\", 'Response': \"Thank you for identifying those thoughts, Tom. We call these 'automatic thoughts' - they pop into our minds quickly and can strongly influence our emotions and actions. Now, let's examine these thoughts more closely. One technique we usually use to question the validity of our automatic thoughts. Are these thoughts factually true? Are there any exceptions to 'She's always criticizing me' or 'Nothing I do is ever good enough'?\" }, { 'Current Summary': \"Through CBT questioning, Tom recognizes that his automatic thoughts contain cognitive distortions, specifically overgeneralization. He acknowledges exceptions to his beliefs about constant criticism and inadequacy. This realization opens the door for cognitive restructuring and behavior modification.\", 'Text': \"Well, when you put it that way... I guess she does compliment me sometimes, especially about how I am with the kids. And she was supportive when I got that promotion last year. Maybe 'always' and 'nothing' are too strong.\", 'Response': \"Excellent observation, Tom. You've just engaged in what we call 'cognitive restructuring' - challenging and modifying unhelpful thought patterns. You've identified that words like 'always' and 'nothing' are overgeneralizations. This is a common cognitive distortion. By recognizing these exceptions, you're starting to see a more balanced view of your relationship with Emma. Now, let's think about how this realization might change your feelings and behaviors in similar situations in the future.\" } ]\n",
        "\n",
        "\n",
        "question_config = [{'Text': \"\", 'Response': \"It seems you haven't you havent shared an input.\", 'Question': \"How can I help you today?\" },{'Text': \"Hi PysOzen, I'm Tom. My wife Emma and I are seriously considering divorce after 15 years of marriage. We're both at our wit's end.\", 'Response': \"I understand you're going through a difficult time, Tom. In situations like these, we focus on how our thoughts affect our feelings and behaviors. This approach can be very helpful in addressing relationship issues.\", 'Question': \"To start, can you identify a specific situation recently that led to conflict between you and Emma?\" }, { 'Text': \"Last night, Emma asked me about my day at work. I gave a short answer because I was tired. She then said, 'You never want to talk to me anymore.' I felt attacked and just walked away. We ended up not speaking for the rest of the evening.\", 'Response': \"Thank you for sharing that specific example, Tom. Let's break this down into thoughts, feelings, and behaviors. You've described your behavior (giving a short answer and walking away) and Emma's response.\", 'Question': \"Now, let's focus on your thoughts. What went through your mind when Emma said, 'You never want to talk to me anymore'?\" }, { 'Text': \"I thought, 'She's always criticizing me. Nothing I do is ever good enough for her. She doesn't understand how hard I work.' It made me feel angry and unappreciated.\", 'Response': \"Thank you for identifying those thoughts, Tom. We refer to these as 'automatic thoughts' - they pop into our minds quickly and can strongly influence our emotions and actions. Now, let's examine these thoughts more closely. One technique we use in situations like these is to question the validity of our automatic thoughts.\", 'Question': \"Are these thoughts factually true? Are there any exceptions to 'She's always criticizing me' or 'Nothing I do is ever good enough'?\" }, { 'Text': \"Well, when you put it that way... I guess she does compliment me sometimes, especially about how I am with the kids. And she was supportive when I got that promotion last year. Maybe 'always' and 'nothing' are too strong.\", 'Response': \"Excellent observation, Tom. You've just engaged in what we call 'cognitive restructuring' - challenging and modifying unhelpful thought patterns. You've identified that words like 'always' and 'nothing' are overgeneralizations. This is a common cognitive distortion. By recognizing these exceptions, you're starting to see a more balanced view of your relationship with Emma.\", 'Question': \"Now, let's think about how this realization might change your feelings and behaviors in similar situations in the future. How do you think you might respond differently next time Emma asks about your day?\" } ]\n",
        "\n",
        "\n",
        "recommendation_config = [{\"User\":[\"Hi PysOzen, I'm Tom. My wife Emma and I are seriously considering divorce after 15 years of marriage.\", \"Last night, Emma asked me about my day at work. I gave a short answer because I was tired. She then said, 'You never want to talk to me anymore.' I felt attacked and just walked away.\", \"I thought, 'She's always criticizing me. Nothing I do is ever good enough for her. She doesn't understand how hard I work.' It made me feel angry and unappreciated.\", \"Well, when you put it that way... I guess she does compliment me sometimes, especially about how I am with the kids. And she was supportive when I got that promotion last year. Maybe 'always' and 'nothing' are too strong.\", \"I could try to give a more detailed answer about my day, even if I'm tired. And maybe explain that I'm feeling drained instead of just walking away.\"], \"Assistant\": [\"I understand you're going through a difficult time, Tom. We will focus on how our thoughts affect our feelings and behaviors. Can you identify a specific situation recently that led to conflict between you and Emma?\", \"Thank you for sharing that example. What thoughts went through your mind when Emma said, 'You never want to talk to me anymore'?\", \"Let's examine these thoughts. Are they factually true? Are there any exceptions to 'She's always criticizing me' or 'Nothing I do is ever good enough'?\", \"Excellent observation, Tom. You've just engaged in cognitive restructuring. Now, let's think about how this realization might change your feelings and behaviors in similar situations in the future. How do you think you might respond differently next time Emma asks about your day?\"], \"Recommendation\": \"Tom, based on our discussion, here are some recommendations to help you apply these insights to your relationship:1. Thought Record: Keep a daily thought record. When you experience strong negative emotions, write down the situation, your automatic thoughts, and your emotional response. Then, challenge these thoughts and write down more balanced alternatives.2. Cognitive Restructuring Practice: Continue to question your automatic thoughts, especially those involving absolutes like 'always' or 'never'. Look for evidence that contradicts these thoughts.3. Behavioral Experiment: Test your beliefs. For instance, for one week, give more detailed responses about your day and express when you're feeling tired. Observe Emma's reactions and compare them to your predictions.4. Communication Skills Training: Practice using 'I' statements to express your feelings without blaming. For example, 'I feel overwhelmed when I come home from work' instead of 'You don't understand how hard I work'.5. Mindfulness Exercises: Incorporate mindfulness techniques to help you stay present and respond thoughtfully rather than react automatically in stressful situations.6. Positive Activity Scheduling: Plan and engage in activities you both enjoy. This can help create positive experiences and challenge the belief that 'nothing is ever good enough'.7. Gratitude Journal: Each day, write down one thing you appreciate about Emma. This can help balance negative thoughts and improve your overall perception of the relationship.8. Regular Check-ins: Schedule short, daily check-ins with Emma where you both share your thoughts and feelings. This can improve communication and challenge the belief that you 'never want to talk'.Remember, changing thought patterns and behaviors takes time and practice. Be patient with yourself and celebrate small improvements. If you find these techniques helpful, consider seeking a couples therapist who can guide you both through this process more comprehensively.\" } ]\n",
        "\n",
        "\n",
        "## Bot config prompt strings\n",
        "\n",
        "summary_kb = \"\\n\".join([f\"Example {i+1}:\\nCurrent Summary: {item['Current Summary']}\\nPrompt: {item['Prompt']}\\nText: {item['Text']}\\nNew Summary: {item['New Summary']}\" for i, item in enumerate(summary_config)])\n",
        "response_kb = \"\\n\".join([f\"Example {i+1}:\\nCurrent Summary: {item['Current Summary']}\\nText: {item['Text']}\\nResponse: {item['Response']}\" for i, item in enumerate(response_config)])\n",
        "question_kb = \"\\n\".join([f\"Example {i+1}:\\nText: {item['Text']}\\nResponse: {item['Response']}\\nQuestion: {item['Question']}\" for i, item in enumerate(question_config)])\n",
        "recommendation_kb = \"\\n\".join([f\"Example {i+1}:\\nUser: {item['User']}\\nAssistant: {item['Assistant']}\\nRecommendation: {item['Recommendation']}\" for i, item in enumerate(recommendation_config)])\n",
        "\n",
        "## Prompt templates\n",
        "\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"current_summary\", \"prompt\", \"text\", \"emotion\"],\n",
        "    template=f\"Use the following examples as a guide to generate a new summary and pass it to response:\\n{summary_kb} based on identified emotions {{emotion}}.\\nCurrent Summary: {{current_summary}}\\nPrompt: {{prompt}}\\nText: {{text}}\\nNew Summary:\"\n",
        ")\n",
        "\n",
        "\n",
        "response_prompt = PromptTemplate(\n",
        "    input_variables=[\"current_summary\", \"text\", \"emotion\"],\n",
        "    template=f\"\"\"The following is a conversation with an AI therapist. The therapist is empathetic, helpful, creative, clever, and very friendly. Use these examples as a guide:\n",
        "\n",
        "{response_kb}\n",
        "\n",
        "Now, generate a response for:\n",
        "Current Summary: {{current_summary}}\n",
        "Text: {{text}}\n",
        "Identofied emotions: {{emotion}} Please me mindful and empatheic while generating the response.\n",
        "Response:\"\"\"\n",
        ")\n",
        "\n",
        "question_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\", \"response\", \"emotion\"],\n",
        "    template=f\"\"\"Use these examples as a guide to generate a follow-up question considering {{emotion}} too:\n",
        "\n",
        "{question_kb}\n",
        "\n",
        "Now, generate a question for:\n",
        "Text: {{text}}\n",
        "Response: {{response}}\n",
        "Please me mindful and empatheic while genrating a question.\n",
        "Question:\"\"\"\n",
        ")\n",
        "\n",
        "recommendation_prompt = PromptTemplate(\n",
        "    input_variables=[\"user\", \"assistant\"],\n",
        "    template=f\"\"\"Following is a sample of conerastion with corresponding recommendation:\n",
        "\n",
        "{recommendation_kb}\n",
        "\n",
        "Now, generate a recommendation for the following conversation:\n",
        "User: {{user}}\n",
        "Assistant: {{assistant}}\n",
        "Recommendation:\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "#llm agent\n",
        "#Create LLMChain\n",
        "#Open AI LLM\n",
        "#Ollma LLM\n",
        "llm = Ollama(model=\"stablelm2\", base_url=\"<local_url>\")\n",
        "\n",
        "\n",
        "## With LangSMith Tracer\n",
        "\n",
        "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "response_chain = LLMChain(llm=llm, prompt=response_prompt)\n",
        "question_chain = LLMChain(llm=llm, prompt=question_prompt)\n",
        "recommendation_chain = LLMChain(llm=llm, prompt=recommendation_prompt)\n",
        "\n",
        "\n",
        "# llm agent\n",
        "\n",
        "# Process function\n",
        "\n",
        "def process_input(state, input, emotions):\n",
        "    # Generate summary\n",
        "    summary = summary_chain.run(current_summary=state['summary'], prompt=state['last_response'], text=input, emotion = str(emotions))\n",
        "    # Generate response\n",
        "    response = response_chain.run(current_summary=summary, text=input, emotion = str(emotions))\n",
        "    # Generate question if needed\n",
        "    if not response.endswith('?'):\n",
        "        question = question_chain.run(text=input, response=response, emotion = str(emotions))\n",
        "        response += ' ' + question\n",
        "\n",
        "    # Update state\n",
        "    state['summary'] = summary\n",
        "    state['last_response'] = response\n",
        "    state['conversation'].append({\"role\": \"user\", \"content\": input})\n",
        "    state['conversation'].append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    return state, response\n",
        "\n",
        "#Llm agent\n",
        "#Condition function\n",
        "\n",
        "def should_continue(state):\n",
        "    # Logic to determine if the conversation should continue\n",
        "    return len(state['conversation']) < 20  # For example, continue for 10 turns\n",
        "\n",
        "#llm agent\n",
        "#Generate recommendations\n",
        "\n",
        "def generate_recommendation(state):\n",
        "    user_convo_list = []\n",
        "    assistant_convo_list = []\n",
        "\n",
        "    for message in state['conversation']:\n",
        "        if message['role'] == 'user':\n",
        "            user_convo_list.append(message['content'])\n",
        "        elif message['role'] == 'assistant':\n",
        "            assistant_convo_list.append(message['content'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    recommendation = recommendation_chain.run(user=user_convo_list, assistant=assistant_convo_list)\n",
        "\n",
        "\n",
        "    state['conversation'].append({\"role\": \"user\", \"content\": \"Generate Recommendation\"})\n",
        "    state['conversation'].append({\"role\": \"assistant\", \"content\": recommendation})\n",
        "    return state, recommendation\n",
        "\n",
        "\n",
        "## llm agent\n",
        "#Lang Graph config\n",
        "\n",
        "# Define the graph\n",
        "\n",
        "# Define the state schema\n",
        "class ChatState(TypedDict):\n",
        "    summary: str\n",
        "    last_response: str\n",
        "    conversation: list\n",
        "\n",
        "workflow = StateGraph(state_schema=ChatState)\n",
        "\n",
        "workflow.add_node(\"process_input\", process_input)\n",
        "workflow.add_node(\"should_continue\", should_continue)\n",
        "workflow.add_node(\"generate_recommendation\", generate_recommendation)\n",
        "\n",
        "\n",
        "# Modify the 'should_continue' function to set the 'next_step'\n",
        "def should_continue(state):\n",
        "    if len(state['conversation']) < 20:\n",
        "        return \"process_input\"\n",
        "    else:\n",
        "        return \"generate_recommendation\"\n",
        "\n",
        "#Use add_edge_with_condition for branching\n",
        "workflow.set_entry_point(\"process_input\")\n",
        "workflow.add_edge(\"process_input\", \"should_continue\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"should_continue\",\n",
        "    {\n",
        "        \"process_input\": process_input,\n",
        "        \"generate_recommendation\": generate_recommendation\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.set_finish_point(\"generate_recommendation\")\n",
        "#workflow.add_edge(\"process_input\", \"should_continue\")\n",
        "#workflow.add_edge(\"should_continue\", \"process_input\")\n",
        "#workflow.add_edge(\"should_continue\", \"generate_recommendation\")\n",
        "\n",
        "#llm agent\n",
        "#Compile langgraph config\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "#Emotion analyzer\n",
        "# Function to analyze emotion from text\n",
        "def analyze_emotion(text):\n",
        "  emotion_analyzer = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
        "  emotions = emotion_analyzer(text)\n",
        "  return emotions\n",
        "\n",
        "def transcribe(file_name):\n",
        "  #audio_file= open(file_name, \"rb\")\n",
        "  #transcription = client.audio.transcriptions.create(\n",
        "  #model=\"whisper-1\",\n",
        "  #file=audio_file)\n",
        "  result = model.transcribe(file_name)\n",
        "  transcript = result[\"text\"]\n",
        "  return transcript\n",
        "\n",
        "def save_audio_file(audio_bytes, file_extension):\n",
        "  timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "  file_name = f\"audio_{timestamp}.{file_extension}\"\n",
        "  with open(file_name, \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "  return file_name\n",
        "\n",
        "def text_to_speech(text):\n",
        "  tts = gTTS(text=text, lang='en')\n",
        "  tts.save(\"response.mp3\")\n",
        "  # Play the audio as before\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    st.title(\"PsyOzen AI Voice Chat Interface\")\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'state' not in st.session_state:\n",
        "      st.session_state.state = {\n",
        "          'summary': \"\",\n",
        "          'last_response': \"Hello, I'm PsyOzen AI. How can I help you today?\",\n",
        "          'conversation': []\n",
        "      }\n",
        "      # Display chat messages from history\n",
        "    for message in st.session_state.state['conversation']:\n",
        "        if type(message) == dict:\n",
        "\n",
        "          with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Accept user input\n",
        "    if prompt := st.chat_input(\"Hello, I'm PsyOzen AI. How can I help you today?\"):\n",
        "        # Add user message to chat history\n",
        "        st.session_state['conversation'].append({\"role\": \"user\", \"content\": prompt})\n",
        "        # Display user message in chat message container\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Record audio input\n",
        "    audio_bytes = audio_recorder(pause_threshold=5.0)\n",
        "    if audio_bytes:\n",
        "        st.audio(audio_bytes, format=\"audio/wav\")\n",
        "        file_name = save_audio_file(audio_bytes, \"wav\")\n",
        "\n",
        "        # Transcribe audio\n",
        "        # Transcribe audio\n",
        "        #with open(file_name, \"rb\") as audio_file:\n",
        "        transcript = transcribe(file_name)\n",
        "          #Emotion analyzer\n",
        "\n",
        "        emotions = analyze_emotion(transcript)\n",
        "\n",
        "        # Process user input\n",
        "        st.session_state.state, response = process_input(st.session_state.state, transcript, emotions)\n",
        "\n",
        "        # Add user message and AI response to conversation\n",
        "        #st.session_state.state['conversation'].append({\"role\": \"user\", \"content\": transcript})\n",
        "        #st.session_state.state['conversation'].append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "        # Display transcribed message\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(transcript)\n",
        "\n",
        "        # Display and speak AI response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.markdown(response)\n",
        "            text_to_speech(response)\n",
        "            audio_file = open('response.mp3', 'rb')\n",
        "            audio_bytes = audio_file.read()\n",
        "            st.audio(audio_bytes, format='audio/mp3')\n",
        "\n",
        "    # Check if we should continue or generate recommendation\n",
        "        next_step = should_continue(st.session_state.state)\n",
        "\n",
        "        if next_step == \"generate_recommendation\":\n",
        "\n",
        "            st.session_state.state, recommendation = generate_recommendation(st.session_state.state)\n",
        "\n",
        "\n",
        "            with st.chat_message(\"assistant\"):\n",
        "              st.markdown(recommendation)\n",
        "\n",
        "              text_to_speech(recommendation)\n",
        "              audio_file = open('response.mp3', 'rb')\n",
        "              audio_bytes = audio_file.read()\n",
        "              st.audio(audio_bytes, format='audio/mp3')\n",
        "\n",
        "\n",
        "\n",
        "        # Clean up temporary files\n",
        "        os.remove(file_name)\n",
        "        os.remove('response.mp3')\n",
        "\n",
        "        # Rerun to update the display\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm_3I_SWKcRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ir2dXm7SHabg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tOQ9L1lHYqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWS4Iv8-tQmJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEwE1_gtElT2",
        "outputId": "a379112c-7303-4515-aae9-6faa18a8a5f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.193.32.67\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv8qUOsdEpDj",
        "outputId": "20263f81-adb2-49f0-8952-1b9d8c5fe4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "changed 22 packages, and audited 23 packages in 1s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "1 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerability\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqC_Vf_gEs2J",
        "outputId": "5c03fe5c-feb9-4eeb-8e89-cb7cb7002d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47642\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.193.32.67:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://many-laws-rule.loca.lt\n",
            "2024-08-28 06:04:47.251781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-28 06:04:47.278302: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-28 06:04:47.286814: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-28 06:04:47.306782: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-28 06:04:48.683922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import Ollama`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import Ollama`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_core.tracers.core:Parent run 5766d6f4-8828-4c7b-bdbc-739b9d60c35d not found for run 335331c7-b977-4d2d-83e0-f91d2cba4183. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run abb5fcbe-d996-4e08-bb2b-15749733b4e2 not found for run ce5de886-865f-4527-a9ee-6e6e5ff7ad0c. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run 816792b4-ec23-484a-a831-bf21ff284e74 not found for run 34125077-8873-4370-9f4e-8da8b0d2a8b6. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import Ollama`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "WARNING:langchain_core.tracers.core:Parent run e905479a-4c10-4343-a10c-bfbebd3c89a5 not found for run c1a26599-14c8-42b0-8566-2bc1c3786616. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run 79b48e70-2976-4178-b657-aa72d1a30684 not found for run 436b49fc-5bad-49be-b156-3da5c28143ab. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run ce29e585-c9e6-48f9-b26b-3233220dcb28 not found for run 476ddf6a-86dc-47e3-9611-735c5336fcb1. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import Ollama`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "WARNING:langchain_core.tracers.core:Parent run 488f43c2-1d57-4e34-9d79-5ec7a3f1a096 not found for run 36766fbf-f2b0-48ee-a534-fa659fdc29c2. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run 07313f6f-61d9-4985-83df-219c08b7c523 not found for run 6d920af5-4535-457d-9f70-9c4623fe3867. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run 1b3663c6-4d26-45a3-80fb-71eff0c0d55d not found for run 55c71fb9-cbde-48ec-937a-db8fefc19e2c. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
            "WARNING:langchain_core.tracers.core:Parent run 1ae50ac9-b30b-47ca-b3a6-ba2019c2f598 not found for run 15aeb724-f87d-4bb9-96ef-52cabb85dea8. Treating as a root run.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & pgrep streamlit & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}